---
title: When AI Helps vs. When It Hurts
---

You've now learned the full picture of AI coding assistants:

- **Chapter 1:** Why they're popular (real productivity benefits)
- **Chapter 2:** The security risks they introduce (48% vulnerability rate)
- **Chapter 3:** Why banning them fails (Shadow AI problem)
- **Chapter 4:** The productivity paradox (works great for some tasks, terrible for others)

Now it's time for the practical framework: **How do you decide when to use AI and when to avoid it?**

This chapter gives you a decision-making framework you can apply immediately â€” whether you're a developer deciding on your next task, a tech lead reviewing a pull request, or an engineering leader setting policy.

## The Decision Framework

Use this simple framework to evaluate any coding task:

```
Should I use AI for this task?

Ask yourself three questions:

1. Is this security-critical? â†’ If YES, avoid AI
2. Is this repetitive/boilerplate? â†’ If YES, AI is great
3. Is this complex/novel logic? â†’ If YES, avoid AI or use with extreme caution

Then apply the override rules:

- Am I a junior developer learning? â†’ AI can help, but verify everything
- Is there a tight deadline? â†’ AI might create more problems than it solves
- Will this code be reviewed by someone senior? â†’ AI is safer with good review
```

<Mermaid chart={`
graph TD
    Start([Evaluate Task]) --> Safety{High Security Risk?}
    Safety -->|YES| Stop[âŒ Don't Use AI]
    Safety -->|NO| Type{Task Type?}
    Type -->|Boilerplate/Tests/Docs| Green[âœ… Great for AI]
    Type -->|Simple Logic| Yellow[ğŸŸ¡ Use with Review]
    Type -->|Complex/Novel| Red[âŒ Avoid AI]`} />

Let's break down each dimension.

## Making the Right Decision: Four Key Dimensions

When deciding whether to use AI for a coding task, evaluate it across four dimensions: security criticality, code complexity, developer experience level, and time pressure. Let's explore each.

**Security Criticality â€” The more security-critical the code, the less you should rely on AI.** ğŸ”´ **Never use AI for** authentication and authorization (login systems, password handling, token generation/validation, access control checks, permission systems) because AI frequently omits security checks or implements them incorrectly, and the cost of getting this wrong is catastrophic. Don't use AI for cryptography (encryption/decryption, key management, hashing algorithms, random number generation for security) because cryptography requires precise implementation where subtle mistakes create major vulnerabilities that are hard to detect. Avoid AI for payment processing (credit card handling, transaction logic, refund workflows, billing calculations) because financial code has strict compliance requirements (PCI-DSS) and regulatory implications that AI doesn't understand. Don't rely on AI for data privacy and compliance (GDPR/CCPA compliance code, PII handling, data retention/deletion, audit logging) because legal and regulatory requirements aren't in AI training data and mistakes can result in fines and lawsuits.

ğŸŸ¡ **Use AI with extreme caution for** API security (rate limiting, input validation, CORS configuration, API authentication) because while AI can scaffold these, you must verify every security control is present and correct. Be cautious with database queries (SQL queries with user input, ORM configurations, database access patterns) because SQL injection and authorization bypass risks are highâ€”always verify parameterization and access checks. Exercise caution with session management (cookie handling, session storage, timeout logic) because AI often suggests insecure defaults and requires expert review.

âœ… **Generally safe to use AI for** non-sensitive CRUD operations (basic create/read/update/delete on non-sensitive data, simple data transformations) because they carry lower security risk, though they still require review for business logic correctness.

**Code Complexity â€” The more complex the logic, the worse AI performs.** âœ… **AI excels at simple, repetitive code** like boilerplate (standard API endpoints, data models/schemas, configuration files, imports and setup) because these follow predictable patterns that AI handles well. AI is great for test scaffolding (unit test structure, mock objects, test data generation, basic assertions) because tests are pattern-based and AI can generate comprehensive coverage quickly. Use AI for code transformations (language translation from Python to JavaScript, API migration from old version to new version, syntax modernization) because mechanical transformations with clear rules work well for AI. AI handles documentation (function docstrings, API documentation, README files, code comments) well because it can infer intent from code structure and generate clear explanations.

ğŸŸ¡ **Use AI cautiously for moderate complexity** like simple business logic (straightforward calculations, basic workflows, simple state machines) because while AI can handle simple logic, you must verify edge cases and business rules carefully. Be cautious with integration code (API client implementations, third-party library usage, SDK integrations) because AI knows common libraries but may suggest outdated or insecure patterns. Exercise care with data processing (ETL pipelines, data validation, format conversions) because while this is pattern-based work AI handles reasonably, edge cases require review.

ğŸ”´ **Avoid AI for high complexity** including complex business logic (multi-step workflows, domain-specific rules, edge case handling, conditional complexity) because AI doesn't understand your business domain and logic errors are common and subtle. Don't rely on AI for system design and architecture (microservices design, database schema design, API design, performance optimization) because these require holistic thinking, tradeoff analysis, and domain expertise that AI lacks. Avoid AI for debugging complex issues (race conditions, memory leaks, performance bottlenecks, distributed systems problems) because debugging requires investigation and context about your specific system that AI doesn't have. Don't use AI for algorithm design (custom algorithms, performance-critical code, novel problem-solving) because AI suggests common solutions, not optimal ones, and algorithmic complexity issues get missed.

**Developer Experience Level â€” Junior developers benefit most from AI but need the most oversight.** For **junior developers (0-2 years)**, AI works well for learning new libraries/frameworks, understanding code patterns, getting unstuck on syntax, and generating boilerplate quickly. However, risks include over-reliance that prevents skill development, not recognizing when AI is wrong, being less equipped to spot security issues, and shipping problematic code quickly. Mitigate these by requiring senior review on all AI-generated code, encouraging juniors to understand rather than just copy, using AI as a teaching tool not a replacement for learning, and pairing junior developers with AI-aware seniors.

For **mid-level developers (2-5 years)**, AI helps with accelerating routine tasks, exploring new technologies, generating tests, and scaffolding projects. Risks include becoming complacent about edge cases, developing false confidence, and skipping proper design thinking. Mitigate by reviewing AI code with the same rigor as human code, using AI for speed not as a substitute for thinking, and applying security checklists to AI-generated code.

For **senior developers (5+ years)**, AI is useful for offloading repetitive work, rapid prototyping, code translation/migration, and documentation. However, seniors may underestimate review time needed, find AI suggestions frustrating or wrong, and spend more time correcting AI than it saves. Mitigate by using AI selectively for clear wins, skipping AI for complex tasks where you're already fast, and focusing on tasks where AI genuinely saves time.

**Time Pressure â€” Tight deadlines make AI more risky, not less.** ğŸ”´ **Avoid AI under time pressure when** you're tempted to skip review ("I'll just ship this, it looks fine"â€”deadline pressure reduces review rigor and AI bugs slip through), the task is high-stakes (production bug fix, critical feature for launch, security patch), or you don't have time to debug (AI-generated bugs can take longer to fix than writing from scratch, and deadline pressure makes thorough debugging harder).

âœ… **AI can help under time pressure for** well-understood, low-risk tasks (boilerplate that's been done many times before, documentation that's overdue, test coverage that needs to increase) and when review is guaranteed (code will definitely be reviewed by senior developer, automated security scanning is in place, time is allocated for fixing issues).

## The AI Readiness Checklist

Before using AI for a task, check these boxes:

### Code Review

- [ ] AI-generated code will be reviewed by an experienced developer
- [ ] Reviewer is aware the code is AI-generated
- [ ] Extra scrutiny will be applied for security issues

### Testing

- [ ] Comprehensive tests will be written (ideally not by AI)
- [ ] Edge cases will be manually verified
- [ ] Security testing will be performed

### Security

- [ ] Code is not security-critical, OR security review is mandatory
- [ ] Static analysis tools will scan the code
- [ ] Dependencies suggested by AI will be vetted

### Understanding

- [ ] I understand what this code does
- [ ] I can explain it to someone else
- [ ] I can debug it if issues arise
- [ ] I can maintain it in the future

### Context

- [ ] AI has enough context to generate appropriate code
- [ ] I'm not sharing sensitive data in prompts
- [ ] Tool being used is approved by organization

**If you can't check all boxes, reconsider using AI for that task.**

## Applying the Framework: Real-World Scenarios

Let's see how the framework works in practice with five common scenarios.

**Scenario 1: Building a REST API for a Todo App** â€” Create CRUD endpoints for todos (non-sensitive data). Analysis: Security-critical? ğŸŸ¢ No (assuming todos aren't sensitive). Complexity? ğŸŸ¢ Low (standard CRUD). Developer level? ğŸŸ¢ Works for all levels. Time pressure? ğŸŸ¢ AI can speed this up. **Decision: âœ… Use AI.** Let AI generate endpoint scaffolding, but review for authorization checks (users shouldn't access others' todos), verify input validation, add tests, and review before merging.

**Scenario 2: Implementing OAuth2 Login** â€” Add Google OAuth authentication to app. Analysis: Security-critical? ğŸ”´ Yes (authentication). Complexity? ğŸŸ¡ Moderate. Developer level? ğŸ”´ Requires expertise. Time pressure? ğŸ”´ Makes it worse. **Decision: âŒ Don't rely on AI.** Instead, use a vetted authentication library, follow official documentation, reference security best practices, and have security team review. (AI can help with non-security parts like UI.)

**Scenario 3: Writing Unit Tests for a Utility Function** â€” Create tests for a date formatting function. Analysis: Security-critical? ğŸŸ¢ No. Complexity? ğŸŸ¢ Low. Developer level? ğŸŸ¢ Works for all. Time pressure? ğŸŸ¢ AI speeds this up. **Decision: âœ… Use AI.** Let AI generate test cases, review for edge cases (timezones, leap years, null values), add any domain-specific cases AI might miss, and run tests to verify they work.

**Scenario 4: Optimizing a Slow Database Query** â€” Fix a query that's timing out. Analysis: Security-critical? ğŸŸ¡ Potentially (depends on query). Complexity? ğŸ”´ High (performance debugging). Developer level? ğŸ”´ Needs expertise. Time pressure? ğŸ”´ Production issue. **Decision: âŒ Don't rely on AI.** Why? AI doesn't have context about your data, performance optimization requires profiling and analysis, AI suggestions might make things worse, and this needs expert investigation. Instead, use profiling tools, analyze query execution plan, and consider AI only for mechanical changes after you've identified the issue.

**Scenario 5: Migrating Code from Python 2 to Python 3** â€” Update syntax and library calls. Analysis: Security-critical? ğŸŸ¡ Review security changes. Complexity? ğŸŸ¢ Mechanical transformation. Developer level? ğŸŸ¢ Works with review. Time pressure? ğŸŸ¢ AI speeds this up significantly. **Decision: âœ… Use AI.** Use AI for syntax transformation, review for deprecated security patterns, test thoroughly, and verify dependencies are updated securely.

Here's a quick reference comparing all five scenarios:

| **Scenario** | **Security** | **Complexity** | **Dev Level** | **Time Pressure** | **Decision** |
|---|:---:|:---:|:---:|:---:|:---:|
| Todo REST API | ğŸŸ¢ Safe | ğŸŸ¢ Low | ğŸŸ¢ All levels | ğŸŸ¢ Helps | âœ… Use AI |
| OAuth2 Login | ğŸ”´ Critical | ğŸŸ¡ Moderate | ğŸ”´ Expert needed | ğŸ”´ Risky | âŒ Avoid |
| Unit Tests | ğŸŸ¢ Safe | ğŸŸ¢ Low | ğŸŸ¢ All levels | ğŸŸ¢ Helps | âœ… Use AI |
| DB Optimization | ğŸŸ¡ Caution | ğŸ”´ High | ğŸ”´ Expert needed | ğŸ”´ Risky | âŒ Avoid |
| Python Migration | ğŸŸ¡ Review | ğŸŸ¢ Low | ğŸŸ¢ With review | ğŸŸ¢ Helps | âœ… Use AI |

**Legend:** ğŸ”´ High risk/Avoid â€¢ ğŸŸ¡ Caution/Review required â€¢ ğŸŸ¢ Safe/Helpful â€¢ âœ… Use AI â€¢ âŒ Don't use AI

## Creating Your Team's AI Guidelines

Use this template to create guidelines for your team:

```markdown
## When to Use AI Coding Assistants

**âœ… Approved Use Cases**
- Boilerplate code (CRUD, configs, schemas)
- Test generation
- Documentation
- Code translation/migration
- Learning new libraries

### ğŸŸ¡ Use With Caution (Requires Senior Review)
- Business logic
- API integrations
- Database queries
- Any code touching user data

**âŒ Prohibited Use Cases**
- Authentication/authorization
- Cryptography
- Payment processing
- Security-critical code
- Production bug fixes without review

### Review Requirements
- All AI-generated code must be marked in PR description
- Security-critical PRs require security team review
- Junior developers' AI-generated code requires senior review
- AI-suggested dependencies must be vetted

### Prompting Guidelines
- Never include credentials, API keys, or secrets
- Don't paste proprietary algorithms or business logic
- Don't share customer data or PII
- Use approved AI tools only (list specific tools)
```

## What's Next?

Congratulations! You've completed Module 1: **The AI Coding Reality Check.** You now understand why AI coding tools are popular, the security risks they introduce, why banning them doesn't work, when they boost productivity versus when they hurt, and how to make smart decisions about when to use them. In **Module 2**, we'll dive deeper into the security risks and how to protect your organization from AI-generated vulnerabilities.

Let's recap everything you've learned: **Chapter 1 (The AI Coding Boom)** covered how AI tools provide real productivity gains on specific tasks, adoption has been explosive due to immediate value, and this is a cultural shift, not a temporary trend. **Chapter 2 (The Dark Side)** revealed that 48% of AI-generated code contains vulnerabilities, 80% of developers incorrectly believe AI code is more secure, and there are six major risk categories from training data to prompt injection. **Chapter 3 (The Shadow AI Problem)** showed that banning AI drives usage underground, 60-70% of developers use unauthorized tools, and shadow AI eliminates visibility and control. **Chapter 4 (The Productivity Paradox)** demonstrated that AI makes you 2x faster on simple tasks but 19% slower on complex tasks, self-reported metrics overestimate gains by 20-24%, and there are hidden costs in review, testing, and maintenance. **Chapter 5 (this chapter)** provided a decision framework based on security, complexity, experience, and time, practical guidelines for different scenarios, and a template for team AI policies.

<Woz 
title="Module 1 Complete" 
description="Test your understanding" 
context="Ask the user 5 questions, one by one, covering key concepts from Module 1 (Chapters 1-5) to ensure they've understood the material before moving to Module 2." 
prompt="I know everything. Ask me woz questions to test my understanding." 
/>

